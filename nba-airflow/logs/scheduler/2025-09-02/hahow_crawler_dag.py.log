[2025-09-02T21:14:51.676+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=90) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:14:51.679+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:14:51.687+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:14:51.686+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:14:59.079+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:15:00.101+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.099+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can edit on DAG:hahow_crawler_dag
[2025-09-02T21:15:00.158+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.155+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can delete on DAG:hahow_crawler_dag
[2025-09-02T21:15:00.199+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.197+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can read on DAG:hahow_crawler_dag
[2025-09-02T21:15:00.235+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.234+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can delete on DAG Run:hahow_crawler_dag
[2025-09-02T21:15:00.272+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.271+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can create on DAG Run:hahow_crawler_dag
[2025-09-02T21:15:00.312+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.312+0800] INFO - override.py:1911 - create_permission() - Created Permission View: menu access on DAG Run:hahow_crawler_dag
[2025-09-02T21:15:00.364+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.363+0800] INFO - override.py:1911 - create_permission() - Created Permission View: can read on DAG Run:hahow_crawler_dag
[2025-09-02T21:15:00.365+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.364+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:15:00.429+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.428+0800] INFO - dag.py:3262 - bulk_write_to_db() - Creating ORM DAG for hahow_crawler_dag
[2025-09-02T21:15:00.482+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:00.481+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-08-31 18:00:00+00:00, run_after=2025-09-01 18:00:00+00:00
[2025-09-02T21:15:00.626+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 8.996 seconds
[2025-09-02T21:15:31.098+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=128) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:15:31.100+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:15:31.104+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:31.103+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:15:32.696+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:15:32.758+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:32.758+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:15:32.824+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:15:32.824+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-08-31 18:00:00+00:00, run_after=2025-09-01 18:00:00+00:00
[2025-09-02T21:15:32.886+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.801 seconds
[2025-09-02T21:16:03.024+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=169) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:03.032+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:16:03.040+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:16:03.038+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:05.879+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:06.202+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:16:06.202+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:16:06.435+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:16:06.434+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-08-31 18:00:00+00:00, run_after=2025-09-01 18:00:00+00:00
[2025-09-02T21:16:06.570+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 3.571 seconds
[2025-09-02T21:16:37.460+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=401) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:37.488+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:16:37.556+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:16:37.534+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:50.999+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:16:51.073+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:16:51.072+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:16:51.193+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 13.944 seconds
[2025-09-02T21:17:21.609+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=483) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:21.615+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:17:21.622+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:21.621+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:24.374+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:24.479+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:24.477+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:17:24.550+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:24.549+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:17:24.606+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 3.017 seconds
[2025-09-02T21:17:54.989+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=575) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:54.994+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:17:55.005+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:55.004+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:58.801+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:17:59.397+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:59.396+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:17:59.578+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:17:59.576+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:17:59.751+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 4.806 seconds
[2025-09-02T21:18:30.699+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=628) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:18:30.702+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:18:30.707+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:18:30.707+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:18:32.264+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:18:32.318+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:18:32.318+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:18:32.370+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:18:32.370+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:18:32.403+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.721 seconds
[2025-09-02T21:19:03.096+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=674) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:03.098+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:19:03.101+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:03.101+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:04.502+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:04.584+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:04.584+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:19:04.651+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:04.651+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:19:04.692+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.606 seconds
[2025-09-02T21:19:34.809+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=715) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:34.814+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:19:34.819+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:34.818+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:36.206+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:19:36.299+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:36.298+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:19:36.358+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:19:36.358+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:19:36.398+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.612 seconds
[2025-09-02T21:20:06.665+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=756) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:06.669+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:20:06.673+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:06.672+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:08.030+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:08.090+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:08.090+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:20:08.134+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:08.134+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:20:08.174+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.523 seconds
[2025-09-02T21:20:38.431+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=797) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:38.435+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:20:38.443+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:38.442+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:40.250+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:20:40.317+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:40.316+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:20:40.373+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:20:40.372+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:20:40.433+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.029 seconds
[2025-09-02T21:21:10.995+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=838) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:10.997+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:21:11.001+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:11.000+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:12.816+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:12.868+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:12.867+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:21:12.915+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:12.915+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:21:12.949+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.967 seconds
[2025-09-02T21:21:43.915+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=882) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:43.917+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:21:43.923+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:43.923+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:45.583+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:21:45.680+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:45.680+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:21:45.730+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:21:45.730+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:21:45.765+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.862 seconds
[2025-09-02T21:22:16.374+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=923) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:16.376+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:22:16.382+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:16.381+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:17.766+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:17.817+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:17.817+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:22:17.871+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:17.871+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:22:17.904+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.548 seconds
[2025-09-02T21:22:48.583+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=964) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:48.586+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:22:48.598+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:48.591+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:50.123+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:22:50.166+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:50.166+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:22:50.210+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:22:50.209+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:22:50.274+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.714 seconds
[2025-09-02T21:23:21.054+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1005) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:21.055+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:23:21.060+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:21.059+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:23.233+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:23.289+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:23.288+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:23:23.355+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:23.354+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:23:23.402+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.367 seconds
[2025-09-02T21:23:53.496+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1043) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:53.503+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:23:53.510+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:53.509+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:55.015+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:23:55.073+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:55.072+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:23:55.112+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:23:55.111+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:23:55.150+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.673 seconds
[2025-09-02T21:24:25.763+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1087) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:24:25.764+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:24:25.768+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:24:25.767+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:24:27.383+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:24:27.455+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:24:27.455+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:24:27.528+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:24:27.527+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:24:27.581+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.838 seconds
[2025-09-02T21:24:58.390+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1128) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:24:58.394+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:24:58.400+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:24:58.399+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:25:00.468+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:25:00.521+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:25:00.520+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:25:00.563+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:25:00.562+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:25:00.602+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.233 seconds
[2025-09-02T21:25:31.410+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1169) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:25:31.412+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:25:31.422+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:25:31.420+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:25:32.960+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:25:33.026+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:25:33.026+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:25:33.079+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:25:33.079+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:25:33.119+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.743 seconds
[2025-09-02T21:26:03.976+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1210) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:03.980+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:26:03.987+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:03.986+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:05.377+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:05.425+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:05.425+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:26:05.477+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:05.476+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:26:05.523+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.579 seconds
[2025-09-02T21:26:36.289+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1251) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:36.290+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:26:36.295+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:36.294+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:38.035+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:26:38.134+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:38.134+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:26:38.215+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:26:38.214+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:26:38.266+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.990 seconds
[2025-09-02T21:27:08.649+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1292) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:08.651+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:27:08.654+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:08.654+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:10.257+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:10.317+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:10.316+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:27:10.376+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:10.376+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:27:10.410+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.777 seconds
[2025-09-02T21:27:41.350+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1333) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:41.361+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:27:41.367+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:41.366+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:43.123+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:27:43.204+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:43.203+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:27:43.290+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:27:43.290+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:27:43.370+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.067 seconds
[2025-09-02T21:28:13.957+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1374) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:13.968+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:28:14.017+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:14.008+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:16.067+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:16.157+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:16.157+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:28:16.238+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:16.237+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:28:16.284+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.450 seconds
[2025-09-02T21:28:47.261+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1415) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:47.264+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:28:47.269+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:47.269+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:49.081+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:28:49.192+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:49.191+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:28:49.293+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:28:49.292+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:28:49.344+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.101 seconds
[2025-09-02T21:29:20.209+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1456) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:20.210+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:29:20.214+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:20.214+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:21.588+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:21.644+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:21.644+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:29:21.690+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:21.690+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:29:21.723+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.528 seconds
[2025-09-02T21:29:52.498+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1497) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:52.500+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:29:52.505+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:52.504+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:54.045+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:29:54.157+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:54.155+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:29:54.236+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:29:54.235+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:29:54.292+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.809 seconds
[2025-09-02T21:30:25.052+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1538) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:25.054+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:30:25.057+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:25.057+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:26.433+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:26.487+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:26.486+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:30:26.532+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:26.531+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:30:26.571+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.529 seconds
[2025-09-02T21:30:57.450+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1579) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:57.453+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:30:57.458+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:57.457+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:58.823+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:30:58.884+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:58.883+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:30:58.978+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:30:58.976+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:30:59.076+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.634 seconds
[2025-09-02T21:31:29.947+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1620) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:31:29.949+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:31:29.952+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:31:29.952+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:31:31.297+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:31:31.351+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:31:31.350+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:31:31.392+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:31:31.392+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:31:31.428+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.494 seconds
[2025-09-02T21:32:02.247+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1661) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:02.249+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:32:02.256+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:02.255+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:03.630+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:03.695+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:03.695+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:32:03.749+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:03.749+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:32:03.813+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.576 seconds
[2025-09-02T21:32:33.916+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1699) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:33.918+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:32:33.922+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:33.921+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:36.806+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:32:36.903+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:36.902+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:32:36.993+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:32:36.992+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:32:37.057+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 3.157 seconds
[2025-09-02T21:33:07.320+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1740) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:07.326+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:33:07.331+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:07.330+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:09.429+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:09.701+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:09.700+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:33:09.883+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:09.883+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:33:09.966+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.664 seconds
[2025-09-02T21:33:40.571+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1786) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:40.573+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:33:40.580+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:40.579+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:42.274+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:33:42.328+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:42.328+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:33:42.384+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:33:42.384+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:33:42.421+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.868 seconds
[2025-09-02T21:34:12.618+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1837) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:12.624+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:34:12.627+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:12.627+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:13.682+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:13.761+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:13.760+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:34:13.874+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:13.873+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:34:13.925+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.317 seconds
[2025-09-02T21:34:44.704+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1878) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:44.706+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:34:44.709+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:44.709+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:45.948+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:34:46.018+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:46.017+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:34:46.094+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:34:46.093+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:34:46.132+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.439 seconds
[2025-09-02T21:35:16.223+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1919) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:16.225+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:35:16.229+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:16.229+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:17.595+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:17.656+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:17.655+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:35:17.699+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:17.698+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:35:17.738+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.524 seconds
[2025-09-02T21:35:47.818+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=1960) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:47.819+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:35:47.822+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:47.822+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:48.933+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:35:49.064+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:49.063+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:35:49.124+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:35:49.123+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:35:49.181+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.373 seconds
[2025-09-02T21:36:19.715+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2001) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:19.717+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:36:19.720+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:19.719+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:21.053+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:21.131+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:21.130+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:36:21.190+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:21.189+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:36:21.245+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.541 seconds
[2025-09-02T21:36:51.953+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2042) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:51.958+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:36:51.963+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:51.962+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:53.276+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:36:53.387+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:53.386+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:36:53.463+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:36:53.462+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:36:53.501+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.559 seconds
[2025-09-02T21:37:24.094+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2083) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:24.100+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:37:24.104+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:24.103+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:25.494+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:25.544+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:25.543+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:37:25.584+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:25.584+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:37:25.620+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.536 seconds
[2025-09-02T21:37:55.821+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2124) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:55.822+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:37:55.826+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:55.825+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:57.021+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:37:57.109+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:57.108+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:37:57.163+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:37:57.162+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:37:57.213+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.403 seconds
[2025-09-02T21:38:27.871+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2165) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:38:27.874+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:38:27.877+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:38:27.876+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:38:29.166+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:38:29.233+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:38:29.231+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:38:29.302+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:38:29.301+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:38:29.373+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.513 seconds
[2025-09-02T21:39:00.031+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2206) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:00.033+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:39:00.037+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:00.037+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:01.075+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:01.145+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:01.144+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:39:01.238+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:01.238+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:39:01.284+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.265 seconds
[2025-09-02T21:39:31.888+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2247) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:31.893+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:39:31.897+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:31.896+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:33.090+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:39:33.192+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:33.191+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:39:33.267+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:39:33.266+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:39:33.310+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.439 seconds
[2025-09-02T21:40:04.075+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2288) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:04.077+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:40:04.081+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:04.081+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:05.598+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:05.671+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:05.670+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:40:05.716+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:05.716+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:40:05.758+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.696 seconds
[2025-09-02T21:40:36.217+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2329) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:36.223+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:40:36.228+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:36.227+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:37.383+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:40:37.495+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:37.495+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:40:37.565+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:40:37.565+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:40:37.616+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.411 seconds
[2025-09-02T21:41:08.243+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2370) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:08.245+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:41:08.249+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:08.248+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:09.384+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:09.512+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:09.512+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:41:09.653+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:09.644+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:41:09.722+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.494 seconds
[2025-09-02T21:41:40.302+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2411) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:40.307+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:41:40.311+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:40.311+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:41.607+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:41:41.674+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:41.673+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:41:41.735+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:41:41.734+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:41:41.779+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.488 seconds
[2025-09-02T21:42:12.679+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2452) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:12.685+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:42:12.690+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:12.689+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:13.894+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:13.960+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:13.960+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:42:14.004+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:14.004+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:42:14.060+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.426 seconds
[2025-09-02T21:42:44.637+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2493) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:44.639+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:42:44.651+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:44.650+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:46.617+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:42:46.688+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:46.688+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:42:46.828+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:42:46.828+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:42:46.942+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.330 seconds
[2025-09-02T21:43:17.152+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2534) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:17.158+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:43:17.162+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:17.161+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:18.678+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:18.765+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:18.764+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:43:18.834+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:18.833+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:43:18.885+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.746 seconds
[2025-09-02T21:43:49.251+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2575) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:49.252+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:43:49.256+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:49.256+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:50.781+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:43:50.820+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:50.819+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:43:50.855+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:43:50.855+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:43:50.886+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.649 seconds
[2025-09-02T21:44:21.298+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2616) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:21.303+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:44:21.308+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:21.307+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:22.541+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:22.598+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:22.598+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:44:22.647+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:22.647+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:44:22.677+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.391 seconds
[2025-09-02T21:44:53.796+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2660) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:53.799+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:44:53.815+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:53.814+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:57.937+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:44:58.120+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:58.120+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:44:58.204+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:44:58.204+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:44:58.353+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 4.710 seconds
[2025-09-02T21:45:28.848+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2723) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:45:28.850+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:45:28.855+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:45:28.854+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:45:30.453+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:45:30.511+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:45:30.510+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:45:30.554+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:45:30.554+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:45:30.595+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.764 seconds
[2025-09-02T21:46:00.816+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2779) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:00.822+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:46:00.827+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:00.826+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:02.315+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:02.374+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:02.374+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:46:02.430+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:02.430+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:46:02.474+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.673 seconds
[2025-09-02T21:46:32.662+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2840) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:32.663+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:46:32.666+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:32.665+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:34.187+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:46:34.230+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:34.230+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:46:34.263+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:46:34.262+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:46:34.295+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.645 seconds
[2025-09-02T21:47:05.151+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2926) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:05.157+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:47:05.161+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:05.160+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:06.402+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:06.451+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:06.450+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:47:06.496+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:06.496+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:47:06.538+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.401 seconds
[2025-09-02T21:47:37.069+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=2972) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:37.071+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:47:37.074+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:37.074+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:38.482+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:47:38.535+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:38.534+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:47:38.576+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:47:38.575+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:47:38.617+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.557 seconds
[2025-09-02T21:48:09.629+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3043) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:09.637+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:48:09.643+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:09.642+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:11.056+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:11.110+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:11.109+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:48:11.154+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:11.153+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:48:11.190+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.580 seconds
[2025-09-02T21:48:41.711+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3114) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:41.714+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:48:41.731+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:41.729+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:44.156+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:48:44.414+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:44.413+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:48:44.497+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:48:44.496+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:48:44.580+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.912 seconds
[2025-09-02T21:49:14.704+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3160) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:14.712+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:49:14.719+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:14.718+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:18.187+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:18.257+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:18.256+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:49:18.334+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:18.334+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:49:18.397+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 3.709 seconds
[2025-09-02T21:49:49.130+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3206) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:49.132+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:49:49.135+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:49.135+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:50.775+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:49:50.836+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:50.835+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:49:50.888+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:49:50.888+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:49:50.943+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.826 seconds
[2025-09-02T21:50:21.593+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3252) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:21.595+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:50:21.597+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:21.597+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:22.869+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:22.991+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:22.990+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:50:23.056+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:23.055+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:50:23.108+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.530 seconds
[2025-09-02T21:50:53.736+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3298) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:53.742+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:50:53.747+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:53.746+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:54.929+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:50:55.013+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:55.013+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:50:55.100+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:50:55.100+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:50:55.177+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.461 seconds
[2025-09-02T21:51:25.954+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3344) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:25.956+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:51:25.964+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:25.963+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:27.204+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:27.257+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:27.256+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:51:27.298+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:27.298+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:51:27.338+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.399 seconds
[2025-09-02T21:51:57.502+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3390) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:57.504+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:51:57.508+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:57.508+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:59.217+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:51:59.283+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:59.282+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:51:59.345+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:51:59.345+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:51:59.386+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.896 seconds
[2025-09-02T21:52:30.030+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3436) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:52:30.104+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:52:30.120+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:52:30.110+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:52:33.587+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:52:33.712+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:52:33.711+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:52:33.826+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:52:33.825+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:52:33.901+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 3.918 seconds
[2025-09-02T21:53:04.329+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3485) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:04.331+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:53:04.336+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:04.335+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:07.067+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:07.161+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:07.160+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:53:07.240+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:07.239+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:53:07.303+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.992 seconds
[2025-09-02T21:53:37.748+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3533) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:37.752+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:53:37.761+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:37.760+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:39.990+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:53:40.175+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:40.174+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:53:40.347+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:53:40.346+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:53:40.454+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.731 seconds
[2025-09-02T21:54:11.047+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3584) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:11.050+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:54:11.055+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:11.054+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:13.105+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:13.212+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:13.212+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:54:13.325+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:13.324+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:54:13.390+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.360 seconds
[2025-09-02T21:54:43.961+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3640) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:43.964+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:54:43.967+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:43.966+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:45.508+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:54:45.607+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:45.606+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:54:45.703+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:54:45.702+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:54:45.761+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.811 seconds
[2025-09-02T21:55:15.911+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3715) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:15.916+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:55:15.924+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:15.923+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:17.818+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:17.979+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:17.977+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:55:18.071+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:18.071+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:55:18.195+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.326 seconds
[2025-09-02T21:55:48.828+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3810) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:48.831+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:55:48.834+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:48.834+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:49.983+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:55:50.072+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:50.071+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:55:50.162+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:55:50.161+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:55:50.198+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.381 seconds
[2025-09-02T21:56:20.409+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3856) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:20.414+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:56:20.419+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:20.419+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:21.530+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:21.568+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:21.567+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:56:21.606+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:21.606+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:56:21.637+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.259 seconds
[2025-09-02T21:56:51.822+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3902) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:51.828+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:56:51.832+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:51.831+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:53.138+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:56:53.200+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:53.199+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:56:53.310+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:56:53.309+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:56:53.348+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.537 seconds
[2025-09-02T21:57:24.057+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3948) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:24.058+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:57:24.062+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:24.061+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:25.035+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:25.075+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:25.075+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:57:25.113+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:25.112+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:57:25.145+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.100 seconds
[2025-09-02T21:57:55.393+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=3994) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:55.406+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:57:55.412+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:55.410+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:56.517+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:57:56.553+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:56.553+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:57:56.590+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:57:56.589+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:57:56.622+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.255 seconds
[2025-09-02T21:58:26.965+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4040) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:58:26.966+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:58:26.973+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:58:26.972+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:58:28.334+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:58:28.393+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:58:28.392+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:58:28.441+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:58:28.440+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:58:28.480+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.528 seconds
[2025-09-02T21:58:59.422+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4086) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:58:59.427+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:58:59.431+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:58:59.431+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:59:00.991+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:59:01.032+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:59:01.032+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:59:01.076+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:59:01.076+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:59:01.117+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.707 seconds
[2025-09-02T21:59:31.317+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4132) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:59:31.320+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T21:59:31.324+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:59:31.324+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:59:32.924+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T21:59:32.971+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:59:32.971+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T21:59:33.011+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T21:59:33.010+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T21:59:33.063+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.763 seconds
[2025-09-02T22:00:04.026+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4178) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:04.028+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:00:04.032+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:04.031+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:05.290+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:05.363+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:05.362+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:00:05.437+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:05.437+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:00:05.537+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.521 seconds
[2025-09-02T22:00:36.234+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4224) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:36.236+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:00:36.241+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:36.240+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:37.479+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:00:37.532+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:37.531+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:00:37.587+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:00:37.587+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:00:37.620+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.397 seconds
[2025-09-02T22:01:08.651+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4270) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:08.652+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:01:08.659+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:08.658+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:09.911+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:09.985+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:09.985+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:01:10.052+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:10.051+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:01:10.091+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.453 seconds
[2025-09-02T22:01:40.529+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4316) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:40.542+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:01:40.551+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:40.550+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:42.593+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:01:42.647+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:42.645+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:01:42.691+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:01:42.691+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:01:42.729+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.238 seconds
[2025-09-02T22:02:13.073+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4362) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:13.074+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:02:13.078+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:13.077+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:14.216+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:14.279+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:14.278+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:02:14.330+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:14.330+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:02:14.407+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.345 seconds
[2025-09-02T22:02:45.370+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4413) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:45.372+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:02:45.377+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:45.376+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:47.001+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:02:47.048+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:47.047+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:02:47.098+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:02:47.097+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:02:47.134+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.778 seconds
[2025-09-02T22:03:17.696+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4459) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:17.697+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:03:17.700+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:17.700+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:18.869+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:19.010+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:19.010+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:03:19.096+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:19.096+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:03:19.133+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.447 seconds
[2025-09-02T22:03:49.679+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4505) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:49.687+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:03:49.693+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:49.692+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:51.303+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:03:51.370+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:51.369+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:03:51.450+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:03:51.449+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:03:51.500+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.836 seconds
[2025-09-02T22:04:21.713+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4551) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:21.715+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:04:21.719+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:21.719+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:22.856+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:22.916+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:22.916+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:04:22.974+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:22.973+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:04:23.020+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.323 seconds
[2025-09-02T22:04:53.304+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4597) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:53.317+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:04:53.336+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:53.335+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:58.557+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:04:58.658+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:58.658+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:04:58.829+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:04:58.828+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:04:58.966+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 5.723 seconds
[2025-09-02T22:05:29.529+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4646) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:05:29.531+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:05:29.536+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:05:29.535+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:05:31.079+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:05:31.148+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:05:31.147+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:05:31.211+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:05:31.211+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:05:31.284+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.766 seconds
[2025-09-02T22:06:02.276+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4692) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:02.278+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:06:02.285+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:02.284+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:03.967+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:04.057+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:04.056+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:06:04.141+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:04.140+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:06:04.186+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.930 seconds
[2025-09-02T22:06:35.106+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4738) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:35.108+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:06:35.113+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:35.112+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:36.703+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:06:36.757+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:36.756+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:06:36.802+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:06:36.801+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:06:36.852+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.759 seconds
[2025-09-02T22:07:07.828+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4784) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:07.831+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:07:07.836+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:07.835+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:09.712+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:09.760+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:09.760+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:07:09.809+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:09.809+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:07:09.856+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.046 seconds
[2025-09-02T22:07:40.821+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4830) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:40.826+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:07:40.854+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:40.853+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:43.067+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:07:43.118+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:43.117+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:07:43.167+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:07:43.167+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:07:43.208+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.429 seconds
[2025-09-02T22:08:13.425+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4873) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:13.433+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:08:13.444+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:13.443+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:15.736+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:15.897+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:15.896+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:08:16.075+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:16.074+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:08:16.192+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.820 seconds
[2025-09-02T22:08:46.726+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4922) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:46.729+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:08:46.732+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:46.731+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:47.980+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:08:48.046+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:48.045+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:08:48.095+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:08:48.094+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:08:48.139+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.424 seconds
[2025-09-02T22:09:18.295+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=4965) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:18.315+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:09:18.330+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:18.329+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:22.469+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:22.581+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:22.580+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:09:22.737+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:22.736+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:09:22.860+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 4.620 seconds
[2025-09-02T22:09:53.116+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5011) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:53.122+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:09:53.130+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:53.128+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:57.772+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:09:57.955+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:57.955+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:09:58.147+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:09:58.146+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:09:58.271+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 5.250 seconds
[2025-09-02T22:10:28.545+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5062) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:10:28.548+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:10:28.559+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:10:28.558+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:10:30.472+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:10:30.552+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:10:30.551+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:10:30.629+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:10:30.628+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:10:30.694+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.178 seconds
[2025-09-02T22:11:00.819+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5116) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:00.825+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:11:00.836+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:00.835+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:02.077+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:02.135+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:02.134+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:11:02.192+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:02.191+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:11:02.242+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.444 seconds
[2025-09-02T22:11:32.745+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5164) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:32.747+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:11:32.760+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:32.759+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:34.276+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:11:34.373+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:34.373+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:11:34.441+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:11:34.441+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:11:34.488+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.769 seconds
[2025-09-02T22:12:05.234+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5215) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:05.240+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:12:05.246+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:05.245+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:06.612+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:06.657+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:06.657+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:12:06.700+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:06.700+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:12:06.733+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.519 seconds
[2025-09-02T22:12:36.917+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5261) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:36.924+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:12:36.932+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:36.930+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:39.388+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:12:39.457+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:39.457+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:12:39.523+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:12:39.522+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:12:39.585+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.694 seconds
[2025-09-02T22:13:09.919+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5307) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:09.921+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:13:09.929+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:09.928+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:11.833+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:11.937+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:11.936+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:13:11.999+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:11.998+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:13:12.068+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 2.175 seconds
[2025-09-02T22:13:42.943+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5353) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:42.949+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:13:42.954+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:42.953+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:46.421+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:13:46.627+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:46.626+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:13:46.795+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:13:46.794+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:13:46.951+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 4.022 seconds
[2025-09-02T22:14:17.320+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5399) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:17.322+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:14:17.326+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:17.325+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:18.520+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:18.577+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:18.576+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:14:18.651+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:18.651+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:14:18.700+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.393 seconds
[2025-09-02T22:14:49.114+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5445) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:49.118+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:14:49.126+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:49.125+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:50.431+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:14:50.484+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:50.484+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:14:50.534+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:14:50.534+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:14:50.574+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.481 seconds
[2025-09-02T22:15:20.872+0800] INFO - processor.py:186 - _handle_dag_file_processing() - Started process (PID=5491) to work on /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:15:20.873+0800] INFO - processor.py:914 - process_file() - Processing file /opt/airflow/dags/hahow_crawler_dag.py for tasks to queue
[2025-09-02T22:15:20.877+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:15:20.876+0800] INFO - dagbag.py:588 - collect_dags() - Filling up the DagBag from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:15:22.181+0800] INFO - processor.py:925 - process_file() - DAG(s) 'hahow_crawler_dag' retrieved from /opt/airflow/dags/hahow_crawler_dag.py
[2025-09-02T22:15:22.217+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:15:22.217+0800] INFO - dag.py:3239 - bulk_write_to_db() - Sync 1 DAGs
[2025-09-02T22:15:22.250+0800] INFO - logging_mixin.py:190 - _propagate_log() - [2025-09-02T22:15:22.250+0800] INFO - dag.py:4180 - calculate_dagrun_date_fields() - Setting next_dagrun for hahow_crawler_dag to 2025-09-01 18:00:00+00:00, run_after=2025-09-02 18:00:00+00:00
[2025-09-02T22:15:22.275+0800] INFO - processor.py:208 - _run_file_processor() - Processing /opt/airflow/dags/hahow_crawler_dag.py took 1.413 seconds
